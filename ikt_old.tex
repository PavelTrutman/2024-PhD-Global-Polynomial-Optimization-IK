\chapter{[Old] Globally optimal solution to the inverse kinematics of 7DOF serial manipulator}\labelcha{ikt}
In this chapter, we describe and review a well-known problem from robotics, the inverse kinematics (IK) problem.
We show how the methods of computing Gr\"obner bases and from polynomial optimization described in \refcha{pol} can be used to solve this problem.

\begin{figure}[h]
\includegraphics[width=0.48\textwidth]{KUKA-LBR-IIWA-Kuhleman-2016.png} \resizebox{0.48\textwidth}{!}{\input{graphs/3D_GB.tex}}
  \caption{(left) 7DOF serial manipulator (\textit{KUKA LBR IIWA}), and (middle) its kinematic model~\cite{Kuhlemann2016}. (right) We can optimally solve its inverse kinematics (green) or find it infeasible (blue) in $99.9$~\% of \num{10000} tested poses.}
  \labelfig{teaser}
\end{figure}

\section{Introduction}
The inverse kinematics problem is one of the most important problems in robotics~\cite{shigley1980theory}.
The problem is to find robot control parameters to bring it into the desired position under the kinematics and collision constraints~\cite{Jazar2007}.

IK problem has been extensively studied in robotics and control~\cite{Raghavan1993InverseKO,Raghavan1995SolvingPS}. The classical formulation~\cite{Raghavan1993InverseKO} of the problem for 6 degrees of freedom (6DOF) serial manipulators leads to solving systems of polynomial equations. This is in general hard (``EXPSPACE complete''~\cite{MAYR1982305}) algebraic computational problem but practical solving methods have been developed for 6DOF manipulators~\cite{Raghavan1993InverseKO,Manocha-Canny1994,Diankov2010}.

An important generalization of the IK problem aims at finding the optimal control parameters for an under-constrained mechanism, i.e.\ when the number of controlled joints in a manipulator is larger than six. Then, an algebraic computation problem turns into an optimization problem over an algebraic variety~\cite{Cox-Little-Shea2015} of possible IK solutions. It is particularly convenient to choose a polynomial objective function in order to arrive at a semi-algebraic optimization problem~\cite{Lasserre}.

Semi-algebraic optimization problems are in general non-convex but can be solved with certified global optimality~\cite{Lasserre2015} using the  Lasserre's hierarchy of convex optimization problems~\cite{Lasserre}.
Computationally, however, semi-algebraic optimization problems are in general extremely hard and were often considered too expensive to be used in practice. In this chapter we show that using ``algebraic pre-processing'', semi-algebraic optimization methods become practical in solving IK problem of general 7DOF serial manipulator with a polynomial objective function.


\subsection{Contribution}
Our main contributions are:
\begin{enumerate}
\item We prove that the variety of IK solutions of all generic 7DOF revolute serial manipulators can be generated by second-degree polynomials only (Theorem~\ref{THM}). This considerably reduces the complexity of semi-algebraic optimization and makes it computationally feasible.

\item We provide a method for computing globally optimal solution to the IK problem for a general 7DOF serial manipulator with a polynomial objective function.

\item We demonstrate that our approach works on a practical 7DOF \textit{KUKA LBR IIWA} manipulator and allows us to solve $99.9$~\% configurations while the straightforward semi-algebraic optimization fails in approx.\ 30~\% of cases.

\item We employ techniques from algebraic geometry~\cite{Cox-Little-Shea2015} and polynomial optimization~\cite{Lasserre2015} to solve the 7DOF IK problem exactly (within the numerical accuracy of computation). Our approach is also able to certify the in-feasibility of solving when it happens. 
%This is only possible thanks to showing that the rotational constraints can be all generated by the second degree polynomials. If original higher degree polynomials were used, the Lasserre relaxation would lead to much larger SDP problems which fail to deliver solutions appear a large number of situations. 
\end{enumerate}

\section{Previous work}
The first breakthrough in solving IK problems was the global solution to IK for a general 6DOF serial manipulator, which was given in~\cite{Raghaven1990,Manocha-Canny1994}. It leads to solving a polynomial system with 16 solutions.
Another important result was the solution to forward kinematics problem of the Stewart-Gough parallel manipulator platform~\cite{Lazard1993} leading to a polynomial system with 40 solutions. See recent work~\cite{Dai2019} for the review of local and other approximate techniques for solving IK problems. We next review only the most relevant work.

\subsection{The most relevant previous work}
The closest previous works are related to solving IK for mechanisms, which are under-constrained when considering positions of the final actuator only. The standard approach is to employ additional dynamics, time optimality, and collision constraints.

In~\cite{Dai2014}, a technique for planning a dynamic whole-body motion of a humanoid robot has been developed. It solves IK as a part of motion planning by local optimization methods taking into account kinematics, dynamics, and collision model. The planning method requires good initialization to converge and depending on the quality of the initialization may take from minutes to hours of running time. Our approach provides globally optimal solution for 7DOF kinematics sub-chains of more complex mechanisms and could be used to initialize kinematic part of motion planning.

Work~\cite{Kuhlemann2016} presented IK solution for 7DOF manipulators with zero link offsets, e.g.\ \textit{KUKA LBR IIWA} manipulators. The solution uses special kinematics of its class of manipulators to decompose the general IK problem to two simpler IK problems that can be solved in a closed form. The one-dimensional variety of self-motions becomes circular and hence the paper proposes to parameterize it by the angle of a point of the circle. Our approach generalizes this solution to a general 7DOF manipulator and shows that it is feasible to solve IK for completely general 7DOF manipulators and optimize over their self-motion varieties.

Paper~\cite{Dai2019} presents a global (approximate) solution to IK for 7DOF manipulators. It formulates IK as a mixed-integer convex optimization program. The key idea of the paper is to approximate the non-convex space of rotations by piecewise linear functions on several intervals that partition the original space. This turns the original non-convex problem into an approximate convex problem when the right interval is chosen. Selecting the values of auxiliary binary variables to pick the actual interval of approximation leads to the integer part of the optimization. This is the first practical globally optimal approach but it is only approximate and as such delivers solutions with errors in units of centimeters and units of degrees. It also fails to detect about 5~\% of infeasible poses. Our approach solves the original problem with sub-$10^{-4}$~mm and sub-$10^{-2}$~degree error and we can solve/decide the feasibility in all but 0.1~\% of tested cases. Computation times of~\cite{Dai2019} and our approach are roughly similar, in units of seconds.

\section{Problem formulation}
Here, we formulate the IK problem for the 7DOF serial manipulators as a semi-algebraic optimization problem with a polynomial objective function.

The task is to find joint coordinates of the manipulator in a way that the end effector reaches the desired pose in space. Since a rigid body in space has 6 DOF, the pose of the end effector is described by six parameters. Typically, three of them represent translation and the other three rotation. Depending on the number and types of the joints, the IK problem can be (i) over-constrained when the manipulator has less than 6 DOF, (ii) well-constraint if it has exactly six DOF, and (iii) under-constrained if it is a kinematically redundant manipulator, i.e.\ has more than six DOF.

IK problem for a manipulator with 6 DOF has a finite number of solutions for reachable generic end effector poses. If more DOFs are added to the manipulator, it becomes more flexible and can move itself even if the end effector pose is fixed, thus producing self-motion.

Having a redundant manipulator brings many advantages, e.g.\ it allows to avoid obstacles in the path, helps to reduce torques and forces, and can avoid singularities. Therefore, by careful positioning better properties of the manipulator can be reached (e.g.\ increased dexterity \cite{Zhou1997}) on previous trajectories and new paths planned where not possible before.

On the other hand, increasing the degrees of freedom increases dramatically the difficulty of the IK problem computation. The IK problem has no longer a finite number of solutions. It can be formulated as a constrained optimization problem choosing the optimal solution from the set of all feasible solutions.

We will next show how the IK problem for 7DOF serial manipulators can be modeled as a polynomial optimization problem (POP).

\subsection{Description by forward kinematics}
We describe manipulators by the Denavit-Hartenberg (D-H) convention~\cite{DH} to construct D-H transformation matrices $M_i(\theta_i)\in\R^{4\times4}$ from the link $i$ to $i-1$. D-H matrices are parametrized by the joint angles $\theta_i$. The product of the D-H matrices for $i$ from $1$ to $7$ gives us the transformation matrix $M$, which represents the transformation from the end effector coordinate system to the base coordinate system
\begin{align}
  \prod_{i=1}^7M_i(\theta_i) &= M.\labeleq{IKT:DKT}
\end{align}
The matrix $M$ consists of the position vector $t\in\R^3$ and the rotation matrix $R\in SO(3)$, which together represent the end effector pose w.r.t.\ the base coordinate system
\begin{align}
  M &= \begin{bmatrix} R & t\\ 0 & 1\end{bmatrix}.
\end{align}
When the joint angles $\theta_i$ are known, a simple evaluation of \refeq{IKT:DKT} gives the end effector pose in the base coordinate system.

Due to kinematic constraints, manipulators come with joint limits, i.e.\ with restrictions on the joint angles $\theta_i$. Typically, maximal $\theta_i^{High}$ and minimal $\theta_i^{Low}$ values of joint angles are given as
\begin{align}
  \theta_i^{Low} &\leq \theta_i \leq \theta_i^{High},\ i=1,\ldots,7. \labeleq{IKT:jointLimits}
\end{align}

\subsection{The inverse kinematics problem}\labelsec{IKT}
The forward kinematics problem is very easy to solve for serial manipulators.
On the other hand, the IK problem is much more difficult since it leads to solving systems of polynomial equations.
To solve the IK problem we set up our desired pose of the end effector in the form of the matrix $M$ and then we can solve \refeq{IKT:DKT} for the joint coordinates $\theta_i$.
For redundant manipulators, there is an infinite number of solutions, and therefore we introduce an objective function to select the solution on which the evaluation of the objective function is minimal. In our case, we prefer the solutions that minimize the maximal distance of each joint angle from zero
\begin{align}
  \min_{\bm{\theta}\in\langle-\pi;\pi)^7} \max_{i=1}^7\|\theta_i\|,\labeleq{IKT:objectiveMinMax}
\end{align}
where $\bm{\theta} = [\theta_1, \ldots, \theta_7]^\top$.
This leads to solutions when the arm of the manipulator is outstretched and straighten, and not folded together in a small amount of space, see \reffig{fig:objective}.
Unfortunately, objective~\refeqb{IKT:objectiveMinMax} is difficult to optimize.
We, therefore, approximate it by a polynomial sum of squares
\begin{align}
  \min_{\bm{\theta}\in\langle-\pi;\pi)^7} \sum_{i=1}^7\theta_i^2.\labeleq{IKT:objectiveSOS}
\end{align}
The biggest contribution to objective~\refeqb{IKT:objectiveSOS} is from the largest angle and thus it is a reasonable approximation of objective~\refeqb{IKT:objectiveMinMax}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.50\textwidth]{angles.pdf}
  \caption{Two solutions of IK problem for a planar manipulator with four revolute joints and an end effector at point $X$ with orientation $\vec{r}$. The blue solution has minimal maximal $\theta_i$ as well as the optimal objective given by \refeq{IKT:objectiveSOS}.}\labelfig{fig:objective}
\end{figure}

Next, we add joint limits and obtain the following optimization problem
\begin{align}
  \arraycolsep=1.4pt
  \begin{array}{lrcl@{\hskip0.5cm}l}
    \multicolumn{5}{l}{\displaystyle \min_{\bm{\theta}\in\langle-\pi;\pi)^7} \sum_{i=1}^7\theta_i^2} \\
    \text{s.t.} & \prod_{i=1}^7M_i(\theta_i) &=& M \\
    & \theta_i^{Low} \leq \theta_i &\leq& \theta_i^{High} & (i = 1,\ldots,7) \\
  \end{array}\labeleq{IKT:optimizationTask}
\end{align}

To be able to use the techniques of polynomial optimization, we need to remove trigonometric functions that are contained in \refeq{IKT:DKT}. We do that by introducing new variables $\bm{c} = [c_1, \ldots, c_7]^\top$ and $\bm{s} = [s_1, \ldots, s_7]^\top$, which represent the cosines and sines of the joint angles $\bm{\theta} = [\theta_1, \ldots, \theta_7]^\top$ respectively. Then, we can rewrite Problem~\refeqb{IKT:optimizationTask} in the new variables. To preserve the structure, we need to add the trigonometric identities
\begin{align}
  q_i(\bm{c}, \bm{s}) &= c_i^2 + s_i^2 -1 = 0,\ i=1,\ldots,7. \labeleq{IKT:q}
\end{align}
\refeq{IKT:DKT} can be directly rewritten as 12 polynomials of degrees up to seven. However, we use the following clever manipulation with the matrix multiplication, which relies on the fact that the inverse of a rotation matrix is its transpose, i.e.\ it is a linear function of the original matrices,
\begin{align}
  \prod_{i=3}^5M_i(\theta_i) - M_2^{-1}(\theta_2)M_1^{-1}(\theta_1)MM_7^{-1}(\theta_7)M_6^{-1}(\theta_6) &= 0 \labeleq{IKT:DH4}
\end{align}
This trick reduces the maximal degree of the polynomials in unknowns $\bm{c}$ and $\bm{s}$ to four.
We denote the polynomials in \refeq{IKT:DH4} as
\begin{align}
  p_j(\bm{c}, \bm{s}) &= 0,\ j = 1,\ldots, 12 \labeleq{IKT:p}
\end{align}
The next step is to rewrite also the objective~\refeqb{IKT:objectiveSOS} as a polynomial in the new variables $\bm{c}$ and $\bm{s}$. We notice that the objective function~\refeqb{IKT:objectiveSOS} is minimal on the same solutions as the following polynomial objective function
\begin{align}
  \min_{\bm{c}\in\langle-1,1\rangle^{7},\ \bm{s}\in\langle-1,1\rangle^7} ||\bm{c}-1||^2.
\end{align}
After rewriting the joint limits inequalities \refeqb{IKT:jointLimits} into the polynomial form, we obtain the following polynomial optimization problem.
\begin{align}
  \arraycolsep=1.4pt
  \begin{array}{lrcl@{\hskip0.5cm}l}
    \multicolumn{5}{l}{\displaystyle \min_{\bm{c}\in\langle-1,1\rangle^{7},\ \bm{s}\in\langle-1,1\rangle^7} ||\bm{c}-1||^2} \\
    \text{s.t.} & p_j(\bm{c}, \bm{s}) &=& 0 & (j = 1,\ldots, 12) \\
    & q_i(\bm{c}, \bm{s}) &=& 0 & (i = 1,\ldots,7) \\
    & -(c_i+1)\tan\frac{\theta_i^{Low}}{2}+s_i &\geq&0 & (i = 1,\ldots,7) \\
    & (c_i+1)\tan\frac{\theta_i^{High}}{2}-s_i &\geq&0 & (i = 1,\ldots,7)
  \end{array}\labeleq{IKT:deg4}
\end{align}
We show how this polynomial optimization problem can be solved in the following sections.

After solving Problem~\refeqb{IKT:deg4}, we recover $\bm{\theta}$ from $\bm{c}$ and $\bm{s}$ by function atan2, which takes into account the signs of the arguments.

\section{Polynomial optimization}\labelsec{POP}
Next, we describe the polynomial optimization methods we use to solve Problem~\refeqb{IKT:deg4}.

Polynomial optimization problems (POPs) are generally non-convex, but they can be solved by Lasserre's hierarchy, which provides global optimality certificates with the help of convex optimization, as surveyed in~\cite{Lasserre2015} and reviewed in \refsec{pol:lass}.

%The idea consists of building a hierarchy of convex optimization problems of increasing size whose values converge to the value of the POP. The convergence proof is based on results of real algebraic geometry, namely the representation of positive polynomials, or Positivstellensatz (PSatz for short). One of the most popular Psatz is due to Putinar, and it expresses a polynomial positive on a compact basic semialgebraic set as a weighted sum of squares (SOS). Finding this SOS representation amounts to solving a semidefinite programming (SDP) problem, a particular convex optimization problem that can be solved efficiently numerically with interior point algorithms. By increasing the degree of the SOS representation, we increase the size of the SDP problem, thereby constructing a hierarchy of SDP problems. Dual to this polynomial positivity problem is the problem of characterizing moments of measures supported on a compact basic semialgebraic set. This also admits an SDP formulation, called moment relaxations, yielding a dual hierarchy, indexed by the so-called relaxation order. The primal-dual hierarchy is called the moment-SOS hierarchy or also the Lasserre hierarchy, since it was first proposed in~\cite{Lasserre2001} in the context of POP with convergence and duality proofs. When the relaxation order increases, the Lasserre hierarchy generates a monotone sequence of superoptimal bounds on the global optimum of a given POP, and results on the moment problems can be used to certify exactness of a given bound, at a finite relaxation order. In this case, it is not necessary to go further in the hierarchy: the non-convex POP is solved at the price of solving a convex SDP problem of given size. A Matlab package GloptiPoly \cite{Henrion2003} has been designed to construct the SDP problems in the hierarchy and solve them with a general purpose SDP solver.

As observed in many applications, the main limitation of the Lasserre's hierarchy (in its original form) is its poor scalability as a function of the number of variables and degree of the POP. This is balanced by the practical observation that, very often, global optimality is certified at the second or third order relaxation. As our experiments reveal, for the degree 4 POP studied in our paper, the third-order relaxation is out of reach of state of the art semidefinite program solvers. It becomes hence critical to investigate reformulation techniques to reduce the degree as much as possible. This is the topic of the next section.

\section{Symbolic reduction of the POP}
Here we provide the description of the algebraic geometry technique we use to reduce the degree of our POP problem to obtain a practical solving method. See~\cite{Cox-Little-Shea2015} for notation and concepts of algebraic geometry.

The POP we have at hand is a constrained with polynomial equations
\begin{align}
f_1=\cdots=f_s=0
\end{align}
of degree $4$ in $\mathbb{Q}[x_1, \ldots, x_n]$. Observe that one can replace
these polynomial equations in the formulation of the POP by any other set of
polynomial equations
\begin{align}
g_1=\cdots=g_t=0
\end{align}
as long as both systems of equations have the same solution set. Natural
candidates for the polynomials $g_i$ can be chosen from the ideal generated by
polynomials $f_1, \ldots, f_s$, i.e.\ the set of algebraic combinations $\Ideal = \{\sum_i q_i
f_i\mid q_i \in \mathbb{Q}[x_1, \ldots, x_n]\}$. It is clear that if all the
polynomials $f_i$ vanish simultaneously at a point, any polynomial $g$ in this set will
vanish at this point.

The difficulty is how to understand the structure of this set and find a nice
finite representation of it that would allow many algebraic operations (such as
deciding whether a given polynomial lies in this set). Solutions have been
brought by symbolic computation, also known as computer algebra, through the development
of algorithms computing Gr\"obner bases. These are finite sets, depending on a monomial ordering~\cite{Cox-Little-Shea2015}, which generate \Ideal{} as input equations do, but from which
the whole structure of the ideal \Ideal{} can be read.

%Modern algorithms for computing Gr\"obner bases ($F4$ and $F5$ algorithms), which significantly improved by several orders of magnitude the state-of-the-art, were introduced next by J.~C.~Faug\`ere~\cite{F4, F5}.
The state of the art algorithms for Gr\"obner bases computation are reviewed in \refsec{pol:mm:algs}.
The contemporary algorithms, which are the \FFFF{} and \FFFFF{} algorithms, bring a linear algebra approach to Gr\"obner bases
computations. In particular, noticing that the intersection of the ideal \Ideal{} with the
subset of polynomials in $\mathbb{Q}[x_1, \ldots, x_n]$ of degree $\leq d$ is a
vector space of finite dimension, is a key to reduce Gr\"obner bases
computations to exact linear algebra operations.

Hence, Gr\"obner bases provide bases of such vector spaces when one uses
monomial orderings which filter monomials w.r.t.\ degree first. Finally, going
back to our problem, a Gr\"obner basis computation allows us to discover if the ideal \Ideal{}
contains degree two polynomials (and is generated by such quadrics).

While this is never the case when starting with generic degree four polynomials, observe that
there are many relations between the coefficients of the degree four equations of
our POP.
Hence, we are not facing a generic situation there and we will see
further that actually a Gr\"obner bases computation provides a set of quadrics
that can replace our initial set of constraints.
Note also that since Gr\"obner
bases algorithms rely on exact linear algebra, such a property holds for any
instance of our POP if it holds for a randomly chosen one (the trace of the
computation will always be the same, giving rise to polynomials of degree $\leq
2$).

\section{Solving the IK problem}
In order to solve the IK problem, we need to solve the optimization problem \refeqb{IKT:deg4}.
First, we apply the implementation GloptiPoly~\cite{gloptipoly} of the method described in \refsec{POP} directly on Problem \refeqb{IKT:deg4}.

\subsection{Direct application of the polynomial solver}
Since the original Problem \refeqb{IKT:deg4} contains polynomials of degrees up to 4, we start with the first possible relaxation of order two. That means we substitute each monomial in the original 14 variables up to degree four by a new variable, and therefore the resulting semidefinite program will have \num{3060} variables.

Solving the second-degree relaxation typically does not yield the solution for this parameterization of the problem, and therefore it is required to go higher in the relaxation hierarchy. Unfortunately, relaxation order three for a polynomial problem in 14 variables leads to a semidefinite problem in \num{38760} variables. Such a huge problem is still often solvable on contemporary computers, but it often takes hours to finish.

\subsection{Symbolic reduction}\labelsec{ikt:sym}
In the view of the previous paragraph, we aim at simplifying the original polynomial problem to be able to obtain solutions even for the relaxation of order two, which takes seconds to solve.

Here is our main result that allows us to do it. We claim that polynomials $p_j$ and $q_i$ of degrees up to four in Problem \refeqb{IKT:deg4} can be reduced to polynomials of degree two.
\begin{theorem}\label{THM}
  The ideal generated by the kinematics constraints \refeqb{IKT:p} for a generic serial manipulator with seven revolute joints and for a generic pose $M$ with the addition of the trigonometric identities \refeqb{IKT:q} can be generated by a set of degree two polynomials.
\end{theorem}
\begin{proof}
  The proof is computational.
  We generate generic instances of serial manipulators and generic poses.
  Then a Gr\"obner basis $G$~\cite{Cox-Little-Shea2015} of polynomials $p_j$ and $q_i$ is computed for each instance of the manipulator and pose.
  We select a subset $S$ of degree two polynomials from the basis $G$ and by computing a new Gr\"obner basis $G^\prime$ from $S$ we verify that $S$ generates the same ideal as the original set of polynomials.
  The procedure of the proof is shown in \reffig{IKT:proof}.
  See Maple code in~\reflis{maple}. The polynomials $p_j$ and $q_i$ are put into the variable \texttt{eq} and the last command of the code will be evaluated to \texttt{True} if the bases $G$ and $G^\prime$ are equal, and therefore generate the same ideal.
  \input{sources/code/maple.tex}
\end{proof}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.4\textwidth]{proof}
  \caption{Steps of the proof of Theorem~\ref{THM}.}
  \labelfig{IKT:proof}
\end{figure}

\subsection{Solving the reduced polynomial optimization problem}
We exploit Theorem \ref{THM} in our approach to solve the IK problem. First, we compute a Gr\"obner basis of the kinematic constraints~\refeqb{IKT:p} and~\refeqb{IKT:q} from which we select only polynomials of degree two. Then, we construct the Problem \refeqb{IKT:deg4} but with polynomial constraints given by the degree two polynomials only.
We solve the problem by hierarchies of semidefinite programs.

Reducing the degree of polynomials from four to two allows us to start with SDP relaxation of order one. The size of this SDP problem, in terms of the number of variables, is now 120. Practical experiments have shown that the first relaxation is not tight enough to yield the solution. On the other hand, the second relaxation gives a solution for almost all poses, see \reftab{ill:results}.

\input{macros/gloptipoly.tex}
\input{macros/GB.tex}
\begin{table*}[ht]
  \centering
  %\renewcommand{\arraystretch}{0.5}
  {\small
  \begin{tabular}{cccccc}\hline
    & \multicolumn{2}{c}{\textbf{Execution time} [s]} & \multicolumn{2}{c}{\textbf{Median error}} & \multirow{2}{*}{\textbf{\% failed}}\\
    & \textbf{Reduction} & \textbf{GloptiPoly} & \textbf{Trans} [mm] & \textbf{Rot} [deg] \\\hline
    Deg.\ 4 pols & ---           & \gloptipolyTimeMeanGloptipoly& \gloptipolyErrorMeanT & \gloptipolyErrorMeanR & \gloptipolyFailed \\
    Deg.\ 2 pols & \GBTimeMeanGB & \GBTimeMeanGloptipoly        & \GBErrorMeanT         & \GBErrorMeanR         & \GBFailed         \\\hline
  \end{tabular}}
  \caption{Overview of execution times and accuracy of the presented methods applied to the \textit{KUKA LBR IIWA} manipulator.}
  \labeltab{ill:results}
\end{table*}

\section{Experiments}
We demonstrate our method on IK problem for \textit{KUKA LBR IIWA} arm with seven revolute joints. The structure of the manipulator is designed in a special way such that the IK problem is simple to compute. One of the advantages is that for a fixed end effector pose the joint angle $\theta_4$ is constant within the self-motion.
This allows for a geometrical derivation of a closed-form solution to the IK problem, such a~\cite{Kuhlemann2016}, where the authors introduce a new angle parameter $\delta$ that fixes the left DOF of the IK problem.

Another approach is to solve the problem by local non-linear optimization techniques~\cite{Buss2004}, but such methods do not provide global optima and the found solution is highly dependent on the initial guess.

Solving the IK problem globally is more computationally challenging. To be able to tackle the problem in a matter of seconds, relaxations of the problem were developed in the past. Dai et al.\ in \cite{Dai2019} proposed mix-integer convex relaxation of the non-convex rotational constraints. Their method finds all classes of solutions that are in correspondence with a different set of active binary variables, but they are unable to select a global optima w.r.t.\ an objective function.

\subsection{Polynomial optimization problem for KUKA LBR IIWA}
When we directly parameterize Problem \refeqb{IKT:deg4} by the D-H parameters of the \textit{KUKA LBR IIWA} manipulator, we obtain POP in 14 variables and with polynomials $p_j$ of degrees up to four.

\subsection{Direct application of the polynomial solver}\labelsec{ill:naive}
First, we solve Problem \refeqb{IKT:deg4} directly by polynomial optimization toolbox GloptiPoly~\cite{gloptipoly} for relaxation order two with the use of MOSEK~\cite{mosek} as the semidefinite problem solver.

Our dataset consists of \num{10000} randomly chosen poses within and outside of the working space of the manipulator as shown in~\reffig{Ill:gloptipoly:3D}. For poses marked by red color, GloptiPoly failed to compute the solution or report infeasibility. That is mainly due to the small relaxation order of the semidefinite relaxation of the POP. There is \gloptipolyFailed{} of such poses which makes this approach quite impractical. Computations for the next degree three relaxation is still often feasible on contemporary computers but takes hours to finish.

\begin{figure}[ht]
  \centering
  \resizebox{0.75\textwidth}{!}{
    \input{graphs/3D_gloptipoly.tex}
  }
  \caption{Generated poses of the manipulator. Green dots are poses marked as feasible by direct solving with GloptiPoly, blue as infeasible, and for the red ones, the computation failed (\gloptipolyFailed).}
  \labelfig{Ill:gloptipoly:3D}
\end{figure}

\subsection{POP with symbolic reduction}
Since the performance of GloptiPoly highly depends on the number of variables of the POP and the relaxation degree, which grows with the degrees of the polynomials contained in the POP, we first symbolically reduce polynomials $p_j$ and $q_i$ and then solve the resulting POP by GloptiPoly.

Firstly, we take advantage of the simplified structure of the \textit{KUKA LBR IIWA} manipulator, i.e.\ that the joint angle $\theta_4$ is constant within the self-motion, and therefore it plays no role in the objective function \refeqb{IKT:objectiveSOS}. That allows us to eliminate the variables $c_4$ and $s_4$ from the equations. Secondly, we reduce the polynomials $p_j$ and $q_j$ symbolically with the use of Theorem~\ref{THM}.

In this way, we have reduced the number of variables from 14 to 12 and we have reduced the degrees of the polynomials to two, which significantly speeds up the semidefinite solver. Practical experiments showed that GloptiPoly is now able to compute IK for more poses with the same relaxation order two than by the na\"ive approach used before, see \reffig{Ill:GB:3D}. Now, only \GBFailed{} of poses failed to be solved on the same dataset as in \refsec{ill:naive}.

\begin{figure}[ht]
  \centering
  \resizebox{0.75\textwidth}{!}{
    \input{graphs/3D_GB.tex}
  }
  \caption{Generated poses of the manipulator. Green dots are poses marked as feasible by GloptiPoly after symbolic simplification, blue as infeasible, and for the red ones, the computation failed (\GBFailed).}
  \labelfig{Ill:GB:3D}
\end{figure}

To verify the numerical stability of the solver we have computed forward kinematics problem based on the found joint angles from the IK problem. Then, we have computed the translation error and rotation error of this pose w.r.t.\ the desired pose. The histogram of the translation and rotation error can be seen in \reffig{Ill:GB:errors}.

\begin{figure}[ht]
  \resizebox{\textwidth}{!}{
    \input{graphs/errors_GB.tex}
  }
  \caption{Histogram of translation and rotation error of the poses computed from the direct kinematics on found solutions w.r.t.\ the desired poses. There are \GBZeroErrorsT{} zero translation errors and \GBZeroErrorsR{} zero rotation errors.}
  \labelfig{Ill:GB:errors}
\end{figure}

For practical applications, the execution time of this method is important. In \reffig{Ill:GB:times}, we show histograms of the execution time of the on-line phase of GloptiPoly as well as of the symbolic reduction of the initial polynomials to degree two polynomials. We observe that our execution times are comparable to computation times in~\cite{Dai2019} when using off-the-shelf polynomial optimization and Gr\"obner bases computation tools. We next plan to develop optimized solvers leading to considerable speedup, as it was done in solving polynomial systems in computer vision~\cite{Larsson2018}.

\begin{figure}[t]
  \resizebox{0.524\textwidth}{!}{
    \input{graphs/timesGloptipoly_GB.tex}
  }%
  \resizebox{0.45\textwidth}{!}{
    \input{graphs/timesMaple_GB.tex}
  }
  \caption{Histograms of execution time. Left: execution time of the on-line phase of GloptiPoly. Right: execution time of the symbolic reduction and elimination in Maple.}
  \labelfig{Ill:GB:times}
\end{figure}

\section{Conclusions}
We presented a practical method for globally solving the 7DOF IK problem with a polynomial objective function. Our solution is accurate and can solve/decide infeasibility in $99.9$~\% cases out of \num{10000} cases tested on the \textit{KUKA LBR IIWA} manipulator. The code is open-sourced at \url{https://github.com/PavelTrutman/Global-7DOF-IKT}.

For future work, we consider two interesting directions. First, it is desirable to return a certificate of infeasibility when POP constraints are incompatible, e.g.\ by computing a sum of squares representation for the polynomial $-1$ on the quadratic module corresponding to the feasible set~\cite{ks13}. Secondly, it is interesting to exploit the structure of our POP to prove the exactness of the observed second semidefinite relaxation in the Lasserre's hierarchy.
%
\hide{
In the case that the POP constraints are incompatible (i.e.\ the feasible set of admissible parameters is empty), it would be desirable to return a certificate of infeasibility. This certificate can be either numerical (obtained by solving the moment-SOS hierarchy with an SDP solver) or symbolic (obtained by Gr\"obner basis methods). It can be obtained e.g.\ by computing an SOS representation for the polynomial -1 (or any other negative polynomial) on the quadratic module corresponding to the feasible set, see e.g.\ \cite{ks13} in the specific case of certifying emptyness of spectrahedra (SDP feasibility sets).

It would be interesting to exploit the specific structure of the POP studied in this paper to prove (maybe under some assumptions on the data) exactness of the first or the second SDP relaxation in the moment-SOS hierarchy, i.e.\ that solving this relaxation always solves the original POP. For Euclidean distance POP arising in computer vision, this was achieved in \cite{aat12} by arguing on the curvature properties of the Lagrangian and its SOS representation in the quadratic module. 
}
% DH: (infeasibility certificates DH, how to get an appropriate formulation of the POP to be able to prove the exactness of the first relaxation DH, )
